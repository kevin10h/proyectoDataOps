import pika
import json
import time
import pandas as pd

# Retry loop para conexi√≥n con RabbitMQ
connection = None
for i in range(20):
    try:
        connection = pika.BlockingConnection(pika.ConnectionParameters(host='rabbitmq'))
        print("[transformer] ‚úÖ Conectado a RabbitMQ.")
        break
    except pika.exceptions.AMQPConnectionError:
        print(f"[transformer] ‚ùå Intento {i+1}: RabbitMQ no disponible. Reintentando en 3s...")
        time.sleep(3)

if not connection:
    raise Exception("üõë No se pudo conectar a RabbitMQ.")

channel = connection.channel()
channel.queue_declare(queue='etl_transform')
channel.queue_declare(queue='etl_load')

def transformacion(df_datos):
    df_datos = df_datos.dropna()
    df_datos['Cantidad Producida'] = pd.to_numeric(df_datos['Cantidad Producida'], errors='coerce')
    df_datos['Costo Unitario ($)'] = pd.to_numeric(df_datos['Costo Unitario ($)'], errors='coerce')
    df_datos['Costo Total ($)'] = pd.to_numeric(df_datos['Costo Total ($)'], errors='coerce')
    # Recalcular el costo total
    df_datos['Costo Total ($)'] = df_datos['Cantidad Producida'] * df_datos['Costo Unitario ($)']
    
    # An√°lisis 1: Costo total por planta de producci√≥n
    df_costo_planta = df_datos.groupby('Planta de Producci√≥n')[['Costo Total ($)']].sum().reset_index()
    # An√°lisis 2: Cantidad producida por categor√≠a
    df_cantidad_categoria = df_datos.groupby(['Categor√≠a', 'Unidad Medida'])[['Cantidad Producida']].sum().reset_index()
    # An√°lisis 3: Costo unitario promedio por m√©todo de transporte
    df_costo_transporte = df_datos.groupby('M√©todo Transporte')[['Costo Unitario ($)']].mean().reset_index()
    # An√°lisis 4: Porcentaje de productos por estado log√≠stico
    df_estado_logistico = df_datos['Estado Log√≠stico'].value_counts(normalize=True).reset_index()
    df_estado_logistico.columns = ['Estado_Logistico', 'Porcentaje']
    # An√°lisis 5: Producci√≥n mensual
    df_datos['Fecha de Producci√≥n'] = pd.to_datetime(df_datos['Fecha de Producci√≥n'], errors='coerce')
    df_produccion_mensual = df_datos.groupby(df_datos['Fecha de Producci√≥n'].dt.to_period("M"))[['Cantidad Producida']].sum().reset_index()
    df_produccion_mensual['Fecha de Producci√≥n'] = df_produccion_mensual['Fecha de Producci√≥n'].astype(str)
    
    return {
        "produccion_general": df_datos,
        "costo_total_por_planta": df_costo_planta,
        "cantidad_por_categoria": df_cantidad_categoria,
        "costo_unitario_por_transporte": df_costo_transporte,
        "estado_logistico": df_estado_logistico,
        "produccion_mensual": df_produccion_mensual
    }

def transformacion_json(df):
    resultado = transformacion(df)
    # Convertir cada DataFrame a JSON con formato 'records'
    for key, df_val in resultado.items():
        resultado[key] = df_val.to_json(orient="records")
    return resultado

def callback(ch, method, properties, body):
    print("[transformer] üì© Mensaje recibido del extractor.")
    try:
        data_json = body.decode()
        df = pd.read_json(data_json, orient="records")
        resultado_transformacion = transformacion_json(df)
        resultado_json = json.dumps(resultado_transformacion)
        channel.basic_publish(
            exchange='',
            routing_key='etl_load',
            body=resultado_json
        )
        print("[transformer] üöÄ Datos transformados enviados a 'etl_load'.")
    except Exception as e:
        print(f"[transformer] ‚ö†Ô∏è Error en transformaci√≥n: {str(e)}")

channel.basic_consume(queue='etl_transform', on_message_callback=callback, auto_ack=True)
print('[transformer] üïí Esperando mensajes en "etl_transform"...')
channel.start_consuming()
# channel.close()